---
title: "MLA CIA2"
author: "loksai 2028031"
date: "16/08/2021"
output: html_document
---


#Here we are working on the movies dataset.
#The problem statement for this dataset is that finding the effect of mobie status when it is compared with all the other variables from the dataset.
#Now we import the dataset in r markdown.

```{r}
data1<-read.csv("C:/Users/LOKSAI/Downloads/archive/movies.csv",stringsAsFactors = TRUE)
str(data1)
```

#By observing the structure of the data1, we have seen that there are factors which are having levels more than 2000 because of this the logistic regression will take infinite time to make model. so we are removing those columns which are having more number of levels.
#And also checking for the null values
```{r}
data1<-data1[,-c(1,3,4,5,8,10,13,14,16)]
View(data1)
sum(is.na(data1))
```

#we can let us see the graph representing the missing values and observed values.
```{r}
library(Amelia)
missmap(data1, main = "Missing Values vs. Observed")
```
# Visualizing dependent variables
```{r}
library(ggplot2)

#Analysing the movie_status dependent variable
ggplot(data1, aes(data1$movie_status))+geom_bar()
```


#Problem statement - Building a Logistic Regression model on dependent variable movie_status (whether the movie is hot or flop based on the independent variables)
#there are only few independent variables has been taken beacuse of very high levels for a factor and the remaining independent variables are gross,budget,genre,runtine,score,rating,votes.


# Dividing the data into train and test data format
```{r}
library(caTools)
set.seed(100)
split1<-sample.split(data1$movie_status,SplitRatio = 0.7)
summary(split1)
datatrain<-subset(data1,split1==TRUE)
datatest<-subset(data1,split1==FALSE)
str(datatrain)
```
# Below we are building Logistic regression for the variable movie_status in the dataset
```{r}
library(blorr)
library(ISLR)
library(caret)
reg1<-train(movie_status~ .,
            method ="glm",
            family = "binomial",
            data=datatrain)
reg1
summary(reg1)
summary(reg1$finalModel)
```
#let us see model fit for our logistic regression
```{r}
library(blorr)
library(Rcpp)

blr_model_fit_stats(reg1$finalModel)

```
#Log Likelihood value is a measure of goodness of fit for any model. Higher the value, better is the model. We should remember that Log Likelihood can lie between -Inf to +Inf. We can only compare the Log Likelihood values between multiple models. So, here our model has -2765.408 has its log likelihood value.

#R-Square value represents how the dependent variable vary with respect to the independent variables in this case all R-Square values are 0.264 that means the dependent variable which is movie_status is varying 26% with respect to all its independent variables.

#AIC and BIC: Akaike Information Criterion(AIC) and Bayesian Information Criterion (BIC) are 2 methods of scoring and selecting model. The score, as defined above, is minimized, e.g. the model with the lowest AIC and BIC is selected. For our model the value of AIC and BIC is 4070.551 and 4264.679 respectively.





# for further analysis we use hosmer lemeshow test
# null hypothesis: model is good fit: resulting accepting the model: as p value is < 0.05 rejecting the null hypothesis
# Alternate hypothesis: model is not good fit.
```{r}
blr_test_hosmer_lemeshow(reg1$finalModel)
```


# Building a confusion matrix
# here below as senstivity is low, we cannot consider the model
# We can change the sensitivity by changing cutoff value
```{r}
blr_confusion_matrix(reg1$finalModel, cutoff = 0.5)
blr_confusion_matrix(reg1$finalModel, cutoff = 0.6)
blr_confusion_matrix(reg1$finalModel, cutoff = 0.3)
```
# Here below we will be finding the fitted values of the coefficients
# Here below we are building predict function and comparing it with test data varibales
# Here below we are building Confusion Matrix for getting predicted accuracy on test data
```{r}
library(blorr)
predict1<-predict(reg1, datatest)
predict1
confusionMatrix(predict1, datatest$movie_status)

```
# now we will build the AIC step forward and both for the final model
```{r}
library(blorr)
regforward<-blr_step_aic_forward(reg1$finalModel, details = TRUE)
plot(regforward)

regboth=blr_step_aic_both(reg1$finalModel, details = TRUE)
plot(regboth)
summary(regboth$model)
```
#This represents the forward step AIC which build by considering each and every variable and train the model the resampling the model will stop where the model gets least AIC values. The graph represents the variables which are significant to the output.



# Building an ROC curve for the dependent variable
# Here the ROC Curve specifies the model fit indices
# From the below graph output we can say that the independent variables has effect in dependent variable
```{r}
gaintable<-blr_gains_table(reg1$finalModel)
blr_roc_curve(gaintable)

```
#ROC curve (Receiver Operating Characteristic curve) is used to specify model fit indices.We can see that there is much area in buldge formed saying that the model is very good model that means independent variables has good effect in predicting the dependent variable movie_status.



# Performing Cross tabulation and chi square test between dependent variable and independent categorical variable

# The below code shows that relatioinship of dependencies between indepedent variable genre and dependent variable movie_status
# Here from chi square test as p-value<0.05 we reject null hypothesis saying that there is a relaitonship between independent and dependent variable.
```{r}
xtabs(~ movie_status + genre, data= datatrain)

table = table(datatrain$movie_status, datatrain$genre)
table
chisq.test(datatrain$movie_status, datatrain$genre)
```
#Chi-Square:

#Null Hypothesis:  No relationship exists on the categorical variables in the population
#Alternative Hypothesis: Relationship exists on the categorical variables in the population 

#The P-Value is 0.02875 which is less than 0.05 so accept the alternative hypothesis and reject null hypothesis. This means that there is relationship between the movie_status and the genre.


```{r}
ttest1<-t.test(datatrain$budget~datatrain$movie_status)
ttest1
summary(ttest1)
```
# Here we are performing t-test for comparing the relationship between Categorical dependent variable and scalar independent variable for finding the perfect columns to be considered

# Here we are comparing dependent variable movie_status (categorical) with independent variable budget (scalar)
# Ho: mu(hit) = mu (flop)
# H1: mu(hit) != mu (flop)
# Here from the below output as p-value<0.05 we are rejecting null hypothesis

#The value of the P is 0.5764 which is greater than 0.05. So, we can accept the null hypothesis and reject the alternative hypothesis. 
#There is a no significance difference in movie_status with respect to budget with 24427872  average on flop and 25170967 avarage on hit.


```{r}
ttest2<-t.test(datatrain$gross~datatrain$movie_status)
ttest2
```
# Here we are comparing dependent variable movie_status (categorical) with independent variable gross (scalar)
# Ho: mu(hit) = mu (flop)
# H1: mu(hit) != mu (flop)
# Here from the below output as p-value<0.05 we are rejecting null hypothesis

#The value of the P is 1.498e-12 which is less than 0.05. So, we can reject the null hypothesis and accept the alternative hypothesis. 
#There is a significance difference in movie_status with respect to gross with  28697175 average on flop and 46568371 average on hit.


```{r}
ttest3<-t.test(datatrain$runtime~datatrain$movie_status)
ttest3
```
# Here we are comparing dependent variable movie_status (categorical) with independent variable runtime (scalar)
# Ho: mu(hit) = mu (flop)
# H1: mu(hit) != mu (flop)
# Here from the below output as p-value<0.05 we are rejecting null hypothesis

#The value of the P is 2.2e-16 which is less than 0.05. So, we can reject the null hypothesis and accept the alternative hypothesis. 
#There is a significance difference in movie_status with respect to runtime with 103.0716 average on flop and 115.8677  average on hit.


```{r}
ttest3<-t.test(datatrain$votes~datatrain$movie_status)
ttest3
```
# Here we are comparing dependent variable movie_status (categorical) with independent variable votes (scalar)
# Ho: mu(hit) = mu (flop)
# H1: mu(hit) != mu (flop)
# Here from the below output as p-value<0.05 we are rejecting null hypothesis

#The value of the P is 2.2e-16 which is less than 0.05. So, we can reject the null hypothesis and accept the alternative hypothesis. 
#There is a significance difference in movie_status with respect to votes with 44195.81 average on flop and 147684.93 average on hit.


# Here we are comparing dependent variable movie_status (categorical) with independent variable year (scalar)
# Ho: mu(hit) = mu (flop)
# H1: mu(hit) != mu (flop)
# Here from the below output as p-value<0.05 we are rejecting null hypothesis
```{r}
ttest3<-t.test(datatrain$year~datatrain$movie_status)
ttest3
```
# Here we are comparing dependent variable movie_status (categorical) with independent variable year (scalar)
# Ho: mu(hit) = mu (flop)
# H1: mu(hit) != mu (flop)
# Here from the below output as p-value<0.05 we are rejecting null hypothesis

#The value of the P is 7.357e-05 which is less than 0.05. So, we can reject the null hypothesis and accept the alternative hypothesis. 
#There is a significance difference in movie_status with respect to year with 2000.660 average on flop and 2001.809 avaerage on hit.


# From above calculation of cross tabulations, chi-square test, t-test between each categorical, scalar independent variable when compared with dependent variable we can say that there is a constant count of effect on dependent variable when comprared with independent variable.
# Here after calculating chi square between the categorical variables and compared it with dependent variable we can say that there are no significant variables.

# Here after performing t test on Categorical dependent variable with all other scalar independent variables we came to know that there are some significant variable.

# Now we are building new regression model without considering the varaibles which are not significant.
# We will be performing Logistic regression to this new dataset
```{r}
library(blorr)
library(ISLR)
library(caret)
reg2<-train(movie_status~ budget+
              gross+
              runtime+
              votes,
            method ="glm",
            family = "binomial",
            data=datatrain)
reg2
summary(reg2)
summary(reg2$finalModel)
```
# before going to final model we need to check model fit
# Finding the model fit
```{r}
library(blorr)
library(Rcpp)

blr_model_fit_stats(reg2$finalModel)
```
#Log Likelihood value is a measure of goodness of fit for any model. Higher the value, better is the model. We should remember that Log Likelihood can lie between -Inf to +Inf. We can only compare the Log Likelihood values between multiple models. So, here our model has -2765.408 has its log likelihood value.

#R-Square value represents how the dependent variable vary with respect to the independent variables in this case all R-Square values are 0.244 that means the dependent variable which is movie_status is varying 26% with respect to all its independent variables.

#AIC and BIC: Akaike Information Criterion(AIC) and Bayesian Information Criterion (BIC) are 2 methods of scoring and selecting model. The score, as defined above, is minimized, e.g. the model with the lowest AIC and BIC is selected. For our model the value of AIC and BIC is 4180.334 and 4212.689 respectively.




# for further analysis we use hosmer lemeshow test
# null hypothesis: model is good fit: resulting accepting the model: as p value is < 0.05 rejecting the null hypothesis
# Alternate hypothesis: model is not good fit.
```{r}
blr_test_hosmer_lemeshow(reg2$finalModel)
```
# Building a confusion matrix
# here below as senstivity is low, we cannot consider the model
# We can change the sensitivity by changing cutoff value
```{r}
blr_confusion_matrix(reg2$finalModel, cutoff = 0.5)
blr_confusion_matrix(reg2$finalModel, cutoff = 0.6)
blr_confusion_matrix(reg2$finalModel, cutoff = 0.3)
```
# Here below we are building steo aic forward and both for our data
```{r}
library(blorr)
regforward<-blr_step_aic_forward(reg2$finalModel, details = TRUE)
plot(regforward)

regboth=blr_step_aic_both(reg2$finalModel, details = TRUE)
plot(regboth)
summary(regboth$model)
```
#This represents the forward step AIC which build by considering each and every variable and train the model the resampling the model will stop where the model gets least AIC values. The graph represents the variables which are significant to the output.

#Finally the model gets less AIC in the model where we consider the votes, budget, runtime and gross variables in the model. That means these independent variables can be used to predict whether the movie is hit or flop.



# Building an ROC curve for the dependent variable
# Here the ROC Curve specifies the model fit indices
# From the below graph output we can say that the independent variables has effect in dependent variable
```{r}
gaintable = blr_gains_table(reg2$finalModel)
blr_roc_curve(gaintable)
```
#ROC curve (Receiver Operating Characteristic curve) is used to specify model fit indices.We can see that there is much area in buldge formed saying that the model is very good model that means independent variables has good effect in predicting the dependent variable movie_status.





